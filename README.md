# SORTED
SORTED: a list of interesting science ideas and links (cognitive/neuro &amp; data science)

<div id="top"></div>

## Open data movement
Open datasets & sites that allow to share different neuroimaging datasets.

### Platforms
* [OpenNeuro](https://openneuro.org): BIDS-compliant MRI, PET, MEG, EEG, and iEEG data 
* [NeuroVault](https://neurovault.org): unthresholded statistical maps, parcellations, and atlases produced by MRI and PET studies

### Other lists
* [openlists/ElectrophysiologyData](https://github.com/openlists/ElectrophysiologyData): EEG, MEG, ECoG/iEEG, and LFP data
* [meagmohit/EEG-Datasets](https://github.com/meagmohit/EEG-Datasets): EEG


<p align="right">(<a href="#top">back to top</a>)</p>

## Tools

### General

* [BIDS](https://bids.neuroimaging.io): Brain Imaging Data Structure; simple and intuitive way to organize and describe neuroimaging and behavioral data
* [Docker](https://www.docker.com): OS-level virtualization to deliver software in packages called containers
* [Protocols.io](https://www.protocols.io): science methods, assays, clinical trials, operational procedures and checklists for keeping your protocols up do date as recommended by Good Laboratory Practice (GLP) and Good Manufacturing Practice (GMP)
* [Sample Consent Forms for neuroimaging research](https://open-brain-consent.readthedocs.io/en/stable/) (EN/DE) | [The Open Brain Consent](https://onlinelibrary.wiley.com/doi/10.1002/hbm.25351)

### MRI / fMRI

* [fMRIPrep](https://fmriprep.org/en/stable/): a preprocessing pipeline for task-based and resting-state fMRI data
* [Neurosynth](https://neurosynth.org): a platform for large-scale, automated synthesis of functional magnetic resonance imaging (fMRI) data

<p align="right">(<a href="#top">back to top</a>)</p>

## Reading corner

### Books

#### Design/ Thinking
* [The Design of Everyday Things](https://en.wikipedia.org/wiki/The_Design_of_Everyday_Things) (Donald Norman): how users use objects, and how to optimize and standardize things and make them more intuitive and user-friendly

#### Programming
* [The Art of Readable Code](https://www.goodreads.com/book/show/8677004-the-art-of-readable-code) (Dustin Boswell & Trevor Foucher): a basic principles and practical techniques that one can apply to write a better code

#### Relaxing on a hammock under a tree...
* [What If? Serious Scientific Answers to Absurd Hypothetical Questions](https://www.goodreads.com/book/show/21413662-what-if-serious-scientific-answers-to-absurd-hypothetical-questions) (Randall Munroe)

### Articles

#### Unreliable Science (*and how to try overcome this issue)

* *Why Most Published Research Findings Are False* (PLOS/ John Ioannidis) | [Paper](https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124) / [Wiki](https://en.wikipedia.org/wiki/Why_Most_Published_Research_Findings_Are_False): an essay written by John Ioannidis (Stanford School of Medicine); author argues that a large number of papers in medical research contain results that in fact cannot be replicated and are a false positive results
* *How scientists fool themselves â€“ and how they can stop* (Nature/ Regina Nuzzo) | [Article](https://www.nature.com/articles/526182a) / [PDF](https://www.nature.com/articles/526182a.pdf): cognitive fallacies in research and debiasing techniques
* *Power failure: why small sample size undermines the reliability of neuroscience* (Nature/ Katherine S. Button et al.) | [Paper](https://www.nature.com/articles/nrn3475): low statistical power and its influence on true/false effects
* *Scanning the horizon: towards transparent and reproducible neuroimaging research* (Nat Rev Neurosci/ Russell A. Poldrack et al.) | [Paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6910649/): problems that should be acknowledge during neuroimaging data analysis (low statistical power, flexibility in data analysis, software errors etc.)
* *Variability in the analysis of a single neuroimaging dataset by many teams* (Nature/ Rotem Botvinik-Nezer et al.) | [Paper](https://www.nature.com/articles/s41586-020-2314-9): analytical flexibility can have substantial effects on scientific conclusions
* *How to get statistically significant effects in any ERP experiment* (and why you shouldn't) (Psychophysiology/ Steven J. Luck & Nicholas Gaspelin) | [Paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5178877/): the purpose of this paper is to demonstrate how common and seemingly innocuous methods for quantifying and analyzing ERP effects can lead to very high rates of significant-but-bogus effects


<p align="right">(<a href="#top">back to top</a>)</p>

## Summer Schools, Courses, Hackathons etc.

* [Neurohackademy](https://neurohackademy.org): a summer school in neuroiming & data science, held at the University of Washington eScience Institute
* [Neuromatch](https://neuromatch.io): Neuromatch Academy (computational techniques crucial both in academia and industry (3-week program)) & Neuromatch Conference (a conference for the computational neuroscience community)
* [Google Summer of Code](https://summerofcode.withgoogle.com): a global, online program focused on bringing new contributors into open source software development

<p align="right">(<a href="#top">back to top</a>)</p>

## Initiatives, research groups, associations...

* [ENIGMA](https://enigma.ini.usc.edu): The ENIGMA Consortium brings together researchers in imaging genomics to understand brain structure, function, and disease, based on brain imaging and genetic data 

<p align="right">(<a href="#top">back to top</a>)</p>

## If you'd like to add anything...

Patrycja | mail[at]ptdz.pl

https://github.com/PTDZ/SORTED

Feel free to edit and create a pull request!
